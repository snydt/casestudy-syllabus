syllabus.md

# Syllabus

## Session 1: Building trust and consensus around the goal of automated decision-making systems

### Mandatory readings
* The [case study](/2021-casestudy-algo.pdf)
* Hao, K. (2020, 20 August). [The UK exam debacle reminds us that algorithms can’t fix broken systems](https://www.technologyreview.com/2020/08/20/1007502/uk-exam-algorithm-cant-fix-broken-system/). MIT Technology Review.
* O’Neil, C. (2016), Introduction and Chapter 1: “Bomb parts: What is a model?”. In _Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy_.

### Optional readings
* Leufer, D. (2020). [Myth: the term AI has a clear meaning](https://www.aimyths.org/the-term-ai-has-a-clear-meaning). AI Myths. 
* Stoyanovich, J. and Arif Khan, F. (2021). [“What is AI?”](https://dataresponsibly.github.io/we-areai/comics/vol1_en.pdf). _We are AI Comics_, Vol 1 (2021). 
* Stoyanovich, J. and Arif Khan, F. (2021). [“Learning from Data”](https://dataresponsibly.github.io/we-are-ai/comics/vol2_en.pdf). _We are AI Comics_, Vol 2 (2021).  

## Session 2: Assessing the risks and impacts of an automated decision-making system

### Mandatory readings 

* Section 1 of the case study: "I.From design to implementation to redress: the many problems of the A-level ADM System". 

* Ada Lovelace Institute (2020, 29 April). [Examining the Black Box: Tools for assessing algorithmic systems](https://www.adalovelaceinstitute.org/report/examining-the-black-box-tools-for-assessing-algorithmic-systems/). 
* Costanza-Chock, S. (2020). ["Design Practices: 'Nothing about Us without Us.'"](https://design-justice.pubpub.org/pub/cfohnud7). In _Design Justice: Community-Led Practices to Build the Worlds We Need_ (1st ed.). 
* Green, B. Z. (2019). [“Chapter 6: The Innovative City: The Relationship between Technical and Nontechnical Change in City Government”](https://doi.org/10.7551/mitpress/11555.003.0008) in _The Smart Enough City: Putting Technology in Its Place to Reclaim Our Urban Future_. MIT Press. 

### Optional readings
* Ada Lovelace Institute. (2020, 30 March). [Final Report of the Citizens’ Biometrics Council](https://www.adalovelaceinstitute.org/project/citizens-biometrics-council/).
* Office for Statistics Regulation Authority. (2021, 2 March). [Ensuring statistical models command public confidence: Learning lessons from the approach to developing models for awarding grades in the UK in 2020,  Executive summary](https://osr.statisticsauthority.gov.uk/publication/ensuring-statistical-models-command-public-confidence/). 
 
## Session 3: Ensuring the technical efficacy of an automated decision-making system

Guest speaker: Dr. Nicolas Berkouk, EPFL.

### Mandatory readings
* Section II of the case study: “‘Black boxed politics’”: the choices behind the tech tools”.

* Angwin, J; Larson, J; Mattu, S.; Kirchner, L. (2016, 23 May). ["Machine Bias: There’s software used across the country to predict future criminals. And it’s biased against blacks."](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) Propublica. 
* Dressel, Julia and Farid, Hany. (2018). The accuracy, fairness, and limits of predicting recidivism. Science Advances. 
* Leufer, D. (2020). [Myth: AI can be objective or unbiased](https://www.aimyths.org/ai-can-be-objective-or-unbiased#bias-in-machine-learning). AI Myths. 
* Stoyanovich, J. and Arif Khan, F. (2021). [“All about that Bias”](https://dataresponsibly.github.io/we-are-ai/comics/vol4_en.pdf). _We are AI Comics, Vol 4_.  

### Optional readings
* Bennett, S. H. (2020, 20 August). [_On A Levels, Ofqual and Algorithms_](https://www.sophieheloisebennett.com/posts/a-levels-2020/). Sophie Bennett’s blog.   
* Suresh, H. and Guttag, J. (2020). [“A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle”](https://arxiv.org/pdf/1901.10002.pdf), Proceedings from the 2020 conference on Fairness, Accountability and Transparency of Machine Learning, Barcelona. 

## Session 4: Setting up feedback loops: transparency, appeals processes

### Mandatory readings
* Ananny, M. and Crawford, K. Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. _New Media & Society_. 2018;20(3):973-989. doi:10.1177/146144481667664
* Jones, E. and Safak, C. (2020, 18 August). [_Can algorithms ever make the grade?_](https://www.adalovelaceinstitute.org/blog/can-algorithms-ever-make-the-grade/). Ada Lovelace Institute’s blog. 
* Szymielewicz, K.; Foryciarz A.; Leufer, D. (2020 January 17). [_Black-Boxed Politics: Opacity is a Choice in AI Systems_](https://medium.com/@szymielewicz/black-boxed-politics-cebc0d5a54ad). Medium [Blog]. 

### Optional readings
* Kolkman, D. (2020, August 16). [_“Fck the algorithm? What the world can learn from the UK A-level grading algorithm fiasco”_](https://blogs.lse.ac.uk/impactofsocialsciences/2020/08/26/fk-the-algorithm-what-the-world-can-learn-from-the-uks-a-level-grading-fiasco/). LSE Impact Blog. 
* Wylie, B. (2018, 13 August). [_Searching for the Smart City's Democratic Future_](https://www.cigionline.org/articles/searching-smart-citys-democratic-future/). Centre for International Governance Innovation. 

## Session 5: “Fck the algorithm”: backlash against ADMS

Guest speaker: [Vidushi Marda](https://vidushimarda.com/).

### Mandatory readings
* Section III of the case study: The aftermath: ADM systems as objects of political discontent.
* Foxglove. (2020, 12 August). [_Press release: UK: Legal action threatened over algorithm used to grade teenagers' exams_](https://www.statewatch.org/news/2020/august/uk-legal-action-threatened-over-algorithm-used-to-grade-teenagers-exams/). Statewatch.org.
* Haskins, C. (2020, 21 April). [_The Los Angeles Police Department Says It Is Dumping A Controversial Predictive Policing Tool_](https://www.buzzfeednews.com/article/carolinehaskins1/los-angeles-police-department-dumping-predpol-predictive). Buzzfeed News.
* Vervloesem, K. (2020, 6 April). [_How Dutch activists got an invasive fraud detection algorithm banned_](https://algorithmwatch.org/en/syri-netherlands-algorithm/). AlgorithmWatch blog. 
* Have a look at the [“Reclaim your Face”](https://reclaimyourface.eu/) campaign, ongoing. 


### Optional: go explore the following websites: 
* Diakopoulos, N. [Algorithm Tips : Resources and leads for investigating algorithms in society.](http://algorithmtips.org/)
* Joshi, D. [AI Observatory.](https://ai-observatory.in/) 
* [Digital Freedom Fund: Advancing Digital Rights in Europe.](https://digitalfreedomfund.org/) 

## Session 6 : Managing the aftermath of an “algorithmic” scandal

### Mandatory readings:
* Green, B. Z. (2019). [“Chapter 2: The Livable City: The Limits and Dangers of New Technology”](https://doi.org/10.7551/mitpress/11555.003.0004) in _The Smart Enough City: Putting Technology in Its Place to Reclaim Our Urban Future_. MIT Press. 
* Ofqual. (2021). [Decisions on how GCSE, AS and A- level grades will be determined in summer 2021](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/965005/6747-1_decisions_-_GQ_consultation_on_awarding_grades_in_2021.pdf). 
* Leufer, D. (2020). [Myth: AI has agency: headline rephraser tool. AI Myths](https://www.aimyths.org/ai-can-be-objective-or-unbiased#bias-in-machine-learning   https://www.aimyths.org/ai-has-agency#headline-rephraser). 
* Poole, S. (2020, 3 September). [Steven Poole’s word of the day: 'Mutant algorithm': boring B-movie or another excuse from Boris Johnson?](https://www.theguardian.com/books/2020/sep/03/mutant-algorithm-boring-b-movie-or-another-excuse-from-boris-johnson). The Guardian.  





syllabus.md

# Syllabus

## Session 1: Building trust and consensus around the goal of automated decision-making systems

### Mandatory readings
* The case study //ADD LINK//
* Hao, K. (2020, 20 August). The UK exam debacle reminds us that algorithms can’t fix broken systems. MIT Technology Review. https://www.technologyreview.com/2020/08/20/1007502/uk-exam-algorithm-cant-fix-broken-system/
* O’Neil, C. (2016), Introduction and Chapter 1: “Bomb parts: What is a model?”. In _Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy_.

### Optional readings
* Leufer, D. (2020). Myth: the term AI has a clear meaning. AI Myths. https://www.aimyths.org/the-term-ai-has-a-clear-meaning 
* Stoyanovich, J. and Arif Khan, F. Julia Stoyanovich and Falaah Arif Khan (2021). “What is AI?”. _We are AI Comics_, Vol 1 (2021) https://dataresponsibly.github.io/we-areai/comics/vol1_en.pdf 
* Stoyanovich, J. and Arif Khan, F. Julia Stoyanovich and Falaah Arif Khan (2021). “Learning from Data”. _We are AI Comics_, Vol 2. https://dataresponsibly.github.io/we-are-ai/comics/vol2_en.pdf 

## Session 2: Assessing the risks and impacts of an automated decision-making system

### Mandatory readings 

* Section 1 of the case study: "I.From design to implementation to redress: the many problems of the A-level ADM System". 

* Ada Lovelace Institute (2020, 29 April). Examining the Black Box: Tools for assessing algorithmic systems. https://www.adalovelaceinstitute.org/report/examining-the-black-box-tools-for-assessing-algorithmic-systems/ 
* Costanza-Chock, S. (2020). "Design Practices: 'Nothing about Us without Us.'". In _Design Justice: Community-Led Practices to Build the Worlds We Need_ (1st ed.). Retrieved from https://design-justice.pubpub.org/pub/cfohnud7  
* Green, B. Z. (2019). “Chapter 6: The Innovative City: The Relationship between Technical and Nontechnical Change in City Government” in _The Smart Enough City: Putting Technology in Its Place to Reclaim Our Urban Future_. MIT Press. DOI: https://doi.org/10.7551/mitpress/11555.003.0008 

### Optional readings
* Ada Lovelace Institute. (2020, 30 March). Final Report of the Citizens’ Biometrics Council. https://www.adalovelaceinstitute.org/project/citizens-biometrics-council/
* Office for Statistics Regulation Authority. (2021, 2 March). Ensuring statistical models command public confidence: Learning lessons from the approach to developing models for awarding grades in the UK in 2020,  Executive summary. https://osr.statisticsauthority.gov.uk/publication/ensuring-statistical-models-command-public-confidence/  
 
## Session 3: Ensuring the technical efficacy of an automated decision-making system

:::tip Guest speaker
Dr. Nicolas Berkouk, EPFL:::

### Mandatory readings
* Section II of the case study: “‘Black boxed politics’”: the choices behind the tech tools”

* Angwin, J ; Larson, J ; Mattu, S. ; Kirchner, L. (2016, 23 May). "Machine Bias: There’s software used across the country to predict future criminals. And it’s biased against blacks."" Propublica. https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
* Dressel, Julia & Farid, Hany. (2018). The accuracy, fairness, and limits of predicting recidivism. Science Advances. 
* Leufer, D. (2020). Myth: AI can be objective or unbiased. AI Myths. https://www.aimyths.org/ai-can-be-objective-or-unbiased#bias-in-machine-learning  
* Stoyanovich, J. and Arif Khan, F. (2021). “All about that Bias”. _We are AI Comics, Vol 4_. https://dataresponsibly.github.io/we-are-ai/comics/vol4_en.pdf 

### Optional readings
* Bennett, S. H. (2020, 20 August). _On A Levels, Ofqual and Algorithms_. Sophie Bennett’s blog. https://www.sophieheloisebennett.com/posts/a-levels-2020/  
* Suresh, H. and Guttag, J. (2020). “A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle”, Proceedings from the 2020 conference on Fairness, Accountability and Transparency of Machine Learning, Barcelona. https://arxiv.org/pdf/1901.10002.pdf

## Session 4: Setting up feedback loops: transparency, appeals processes

### Mandatory readings
* Ananny M, Crawford K. Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. _New Media & Society_. 2018;20(3):973-989. doi:10.1177/146144481667664
* Jones, E. and Safak, C. (2020, 18 August). _Can algorithms ever make the grade?_. Ada Lovelace Institute’s blog. https://www.adalovelaceinstitute.org/blog/can-algorithms-ever-make-the-grade/ 
* Szymielewicz, K.; Foryciarz A.; Leufer, D. (2020 January 17). _Black-Boxed Politics: Opacity is a Choice in AI Systems_. Medium [Blog]. https://medium.com/@szymielewicz/black-boxed-politics-cebc0d5a54ad 

### Optional readings
* Kolkman, D. (2020, August 16). _“Fck the algorithm? What the world can learn from the UK A-level grading algorithm fiasco”_. LSE Impact Blog. https://blogs.lse.ac.uk/impactofsocialsciences/2020/08/26/fk-the-algorithm-what-the-world-can-learn-from-the-uks-a-level-grading-fiasco/ 
* Wylie, B. (2018, 13 August). _Searching for the Smart City's Democratic Future_. Centre for International Governance Innovation. https://www.cigionline.org/articles/searching-smart-citys-democratic-future/ 

## Session 5: “Fck the algorithm”: backlash against ADMS

:::tip Guest speaker
Vidushi Marda:::

### Mandatory readings
* Section III of the case study: The aftermath: ADM systems as objects of political discontent
* Foxglove. (2020, 12 August). _Press release: UK: Legal action threatened over algorithm used to grade teenagers' exams_. Statewatch.org. https://www.statewatch.org/news/2020/august/uk-legal-action-threatened-over-algorithm-used-to-grade-teenagers-exams/ 
* Haskins, C. (2020, 21 April). _The Los Angeles Police Department Says It Is Dumping A Controversial Predictive Policing Tool_. Buzzfeed News. https://www.buzzfeednews.com/article/carolinehaskins1/los-angeles-police-department-dumping-predpol-predictive 
* Vervloesem, K. (2020, 6 April). _How Dutch activists got an invasive fraud detection algorithm banned_. AlgorithmWatch blog.  https://algorithmwatch.org/en/syri-netherlands-algorithm/
* Have a look at the “Reclaim your Face” campaign, ongoing. https://reclaimyourface.eu/ 


### Optional: go explore the following websites: 
* Diakopoulos, N. [Algorithm Tips : Resources and leads for investigating algorithms in society.](http://algorithmtips.org/)
* Joshi, D. [AI Observatory.](https://ai-observatory.in/) 
* [Digital Freedom Fund: Advancing Digital Rights in Europe.](https://digitalfreedomfund.org/) 

## Session 6 : Managing the aftermath of an “algorithmic” scandal

### Mandatory readings:
* Green, B. Z. (2019). “Chapter 2: The Livable City: The Limits and Dangers of New Technology” in _The Smart Enough City: Putting Technology in Its Place to Reclaim Our Urban Future_. MIT Press. 2: The Livable City: The Limits and Dangers of New Technology DOI https://doi.org/10.7551/mitpress/11555.003.0004
* Ofqual. (2021). Decisions on how GCSE, AS and A- level grades will be determined in summer 2021. https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/965005/6747-1_decisions_-_GQ_consultation_on_awarding_grades_in_2021.pdf
* Leufer, D. (2020). Myth: AI has agency: headline rephraser tool. AI Myths. https://www.aimyths.org/ai-can-be-objective-or-unbiased#bias-in-machine-learning   https://www.aimyths.org/ai-has-agency#headline-rephraser 
* Poole, S. (2020, 3 September). Steven Poole’s word of the day: 'Mutant algorithm': boring B-movie or another excuse from Boris Johnson?. The Guardian. https://www.theguardian.com/books/2020/sep/03/mutant-algorithm-boring-b-movie-or-another-excuse-from-boris-johnson 




